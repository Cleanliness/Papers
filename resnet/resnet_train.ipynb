{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wARRX0_ZBXDa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[3m                                ResBlock Summary                                \u001b[0m\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1mpath      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mbatch_sta…\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
            "│            │ ResBlock  │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │             │            │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Conv_0     │ Conv      │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │ bias:       │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │            │\n",
            "│            │           │             │            │ kernel:     │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[3,… │            │\n",
            "│            │           │             │            │             │            │\n",
            "│            │           │             │            │ \u001b[1m1,792 \u001b[0m\u001b[1;2m(7.2 \u001b[0m │            │\n",
            "│            │           │             │            │ \u001b[1;2mKB)\u001b[0m         │            │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│ BatchNorm… │ BatchNorm │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │ bias:       │ mean:      │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │           │             │            │ scale:      │ var:       │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │           │             │            │             │            │\n",
            "│            │           │             │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │           │             │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Conv_1     │ Conv      │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │ bias:       │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │            │\n",
            "│            │           │             │            │ kernel:     │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[3,… │            │\n",
            "│            │           │             │            │             │            │\n",
            "│            │           │             │            │ \u001b[1m36,928 \u001b[0m     │            │\n",
            "│            │           │             │            │ \u001b[1;2m(147.7 KB)\u001b[0m  │            │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│ BatchNorm… │ BatchNorm │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │ bias:       │ mean:      │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │           │             │            │ scale:      │ var:       │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │ \u001b[2mfloat32\u001b[0m[6… │\n",
            "│            │           │             │            │             │            │\n",
            "│            │           │             │            │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 B)\u001b[0m │ \u001b[1m128 \u001b[0m\u001b[1;2m(512 \u001b[0m  │\n",
            "│            │           │             │            │             │ \u001b[1;2mB)\u001b[0m         │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│ Dense_0    │ Dense     │ \u001b[2mfloat32\u001b[0m[1,… │ \u001b[2mfloat32\u001b[0m[1… │ bias:       │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[64] │            │\n",
            "│            │           │             │            │ kernel:     │            │\n",
            "│            │           │             │            │ \u001b[2mfloat32\u001b[0m[3,… │            │\n",
            "│            │           │             │            │             │            │\n",
            "│            │           │             │            │ \u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m   │            │\n",
            "│            │           │             │            │ \u001b[1;2mKB)\u001b[0m         │            │\n",
            "├────────────┼───────────┼─────────────┼────────────┼─────────────┼────────────┤\n",
            "│\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m     Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m39,232     \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m256 \u001b[0m\u001b[1;2m(1.0 \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\n",
            "│\u001b[1m            \u001b[0m│\u001b[1m           \u001b[0m│\u001b[1m             \u001b[0m│\u001b[1m            \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2m(156.9 KB)\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
            "└────────────┴───────────┴─────────────┴────────────┴─────────────┴────────────┘\n",
            "\u001b[1m                                                                                \u001b[0m\n",
            "\u001b[1m                      Total Parameters: 39,488 \u001b[0m\u001b[1;2m(158.0 KB)\u001b[0m\u001b[1m                       \u001b[0m\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-21 14:45:46.936482: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-21 14:45:46.936544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-21 14:45:46.963576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-21 14:45:48.046901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/home/roy/miniconda3/envs/jaxnn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from resblock import ResBlock\n",
        "\n",
        "# dataset loading\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# training\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "from flax import struct                # Flax dataclasses\n",
        "import optax                           # Common loss functions and optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN4FHLgRB0MF"
      },
      "source": [
        "### Dataset Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g8It209jBs1d"
      },
      "outputs": [],
      "source": [
        "def get_datasets(num_epochs, batch_size):\n",
        "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
        "  train_ds = tfds.load('mnist', split='train')\n",
        "  test_ds = tfds.load('mnist', split='test')\n",
        "\n",
        "  train_ds = train_ds.map(lambda sample: {'image': tf.cast(sample['image'],\n",
        "                                                           tf.float32) / 255.,\n",
        "                                          'label': sample['label']}) # normalize train set\n",
        "  test_ds = test_ds.map(lambda sample: {'image': tf.cast(sample['image'],\n",
        "                                                         tf.float32) / 255.,\n",
        "                                        'label': sample['label']}) # normalize test set\n",
        "\n",
        "  train_ds = train_ds.repeat(num_epochs).shuffle(1024) # create shuffled dataset by allocating a buffer size of 1024 to randomly draw elements from\n",
        "  train_ds = train_ds.batch(batch_size, drop_remainder=True).prefetch(1) # group into batches of batch_size and skip incomplete batch, prefetch the next sample to improve latency\n",
        "  test_ds = test_ds.shuffle(1024) # create shuffled dataset by allocating a buffer size of 1024 to randomly draw elements from\n",
        "  test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1) # group into batches of batch_size and skip incomplete batch, prefetch the next sample to improve latency\n",
        "\n",
        "  return train_ds, test_ds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Identical to architecture defined in original ResNet paper\n",
        "    \"\"\"\n",
        "    stack_s_size: int = 3\n",
        "    stack_m_size: int = 4\n",
        "    stack_l_size: int = 6\n",
        "    num_classes: int = 10\n",
        "    pool: nn.Module = nn.avg_pool\n",
        "    linear: nn.Module = nn.Dense\n",
        "\n",
        "    def setup(self):\n",
        "        self.stack_s = nn.Sequential(\n",
        "            [ResBlock(64) for _ in range(self.stack_s_size)]\n",
        "        )\n",
        "        self.stack_m = nn.Sequential(\n",
        "            [ResBlock(128) for _ in range(self.stack_m_size)]\n",
        "        )\n",
        "        self.stack_l = nn.Sequential(\n",
        "            [ResBlock(256) for _ in range(self.stack_l_size)]\n",
        "        )\n",
        "\n",
        "        # output logits\n",
        "        self.fc_final = nn.Dense(self.num_classes) \n",
        "    \n",
        "\n",
        "    def __call__(self, x):\n",
        "\n",
        "        B = x.shape[0]\n",
        "\n",
        "        x = self.stack_s(x)\n",
        "        x = self.stack_m(x)\n",
        "\n",
        "        x = self.stack_l(x)\n",
        "        x = self.pool(x, (2, 2), (2, 2))\n",
        "        x = x.reshape((B, -1))\n",
        "        x = self.fc_final(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing out on dummy input\n",
        "\n",
        "Outputs:\n",
        "- [0] Final FC layer activations\n",
        "- [1] batch_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 10)\n"
          ]
        }
      ],
      "source": [
        "b = ResNet()\n",
        "rng = jax.random.PRNGKey(0)\n",
        "\n",
        "params = b.init(rng, jnp.ones((5, 28, 28, 3)))\n",
        "# test the forward pass\n",
        "logits = b.apply(params, jnp.ones((5, 28, 28, 3)), mutable=['batch_stats'])\n",
        "# print(params)\n",
        "print(logits[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_accuracy(logits, labels):\n",
        "  return jnp.mean(jnp.argmax(logits, -1) == labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training State\n",
        "This bundles everything related to one training run:\n",
        "- model parameters\n",
        "- hyperparameters\n",
        "- optimizers\n",
        "- etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_state(model, rng, in_shape, hp):\n",
        "    \"\"\"\n",
        "    create train state given\n",
        "    model: nn.Module\n",
        "    rng: PRNGKey\n",
        "    in_shape: input shape\n",
        "    hp: hyperparameters dict\n",
        "    \"\"\"\n",
        "\n",
        "    params = model.init(rng, jnp.ones(in_shape))\n",
        "    optim = optax.adam(learning_rate=hp['lr'])\n",
        "\n",
        "    return train_state.TrainState.create(\n",
        "        apply_fn=model.apply,\n",
        "        params=params,\n",
        "        tx=optim\n",
        "    )\n",
        "\n",
        "# hyperparameters\n",
        "hp = {\n",
        "    'lr': 0.0001,\n",
        "    'batch_size': 32,\n",
        "    'num_epochs': 10\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @jax.jit\n",
        "def train_step(train_state, X, t):\n",
        "    \"\"\"\n",
        "    train step\n",
        "    \"\"\"\n",
        "    def loss_fn(params):\n",
        "        logits = train_state.apply_fn(params, X, mutable=['batch_stats'])[0]\n",
        "        # print(logits.shape, t.shape)\n",
        "        t_onehot = jax.nn.one_hot(t, 10)\n",
        "        loss = optax.softmax_cross_entropy(logits=logits, labels=t_onehot)\n",
        "        loss = jnp.mean(loss)\n",
        "        return loss, logits\n",
        "    \n",
        "    # function that computes function value and gradient\n",
        "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "    (loss, logits), grad = grad_fn(train_state.params)\n",
        "\n",
        "    print(\"accuracy: \", get_accuracy(logits, t))\n",
        "    # update parameters\n",
        "    updates, new_opt_state = train_state.tx.update(grad, train_state.opt_state, train_state.params)\n",
        "    new_params = optax.apply_updates(train_state.params, updates)\n",
        "    new_state = train_state.replace(params=new_params, opt_state=new_opt_state)\n",
        "    return new_state, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy:  0.0625\n",
            "Batch 0 loss: 2.3010637760162354\n",
            "accuracy:  0.03125\n",
            "Batch 1 loss: 2.3257012367248535\n",
            "accuracy:  0.0\n",
            "Batch 2 loss: 2.321312665939331\n",
            "accuracy:  0.1875\n",
            "Batch 3 loss: 2.2949609756469727\n",
            "accuracy:  0.28125\n",
            "Batch 4 loss: 2.2787766456604004\n",
            "accuracy:  0.25\n",
            "Batch 5 loss: 2.2432780265808105\n",
            "accuracy:  0.125\n",
            "Batch 6 loss: 2.2875819206237793\n",
            "accuracy:  0.15625\n",
            "Batch 7 loss: 2.300485610961914\n",
            "accuracy:  0.375\n",
            "Batch 8 loss: 2.128314971923828\n",
            "accuracy:  0.375\n",
            "Batch 9 loss: 2.0713255405426025\n",
            "accuracy:  0.375\n",
            "Batch 10 loss: 1.9635430574417114\n",
            "accuracy:  0.46875\n",
            "Batch 11 loss: 1.5138872861862183\n",
            "accuracy:  0.40625\n",
            "Batch 12 loss: 1.3324579000473022\n",
            "accuracy:  0.5\n",
            "Batch 13 loss: 1.4267290830612183\n",
            "accuracy:  0.625\n",
            "Batch 14 loss: 1.0227885246276855\n",
            "accuracy:  0.65625\n",
            "Batch 15 loss: 1.4378671646118164\n",
            "accuracy:  0.59375\n",
            "Batch 16 loss: 1.1241247653961182\n",
            "accuracy:  0.625\n",
            "Batch 17 loss: 1.2397819757461548\n",
            "accuracy:  0.71875\n",
            "Batch 18 loss: 0.8037732839584351\n",
            "accuracy:  0.5625\n",
            "Batch 19 loss: 1.1291024684906006\n",
            "accuracy:  0.5625\n",
            "Batch 20 loss: 0.9710503816604614\n",
            "accuracy:  0.53125\n",
            "Batch 21 loss: 1.2447872161865234\n",
            "accuracy:  0.59375\n",
            "Batch 22 loss: 1.0204161405563354\n",
            "accuracy:  0.75\n",
            "Batch 23 loss: 0.8133347034454346\n",
            "accuracy:  0.78125\n",
            "Batch 24 loss: 0.6020656824111938\n",
            "accuracy:  0.78125\n",
            "Batch 25 loss: 0.7233312129974365\n",
            "accuracy:  0.78125\n",
            "Batch 26 loss: 0.5227624177932739\n",
            "accuracy:  0.78125\n",
            "Batch 27 loss: 0.5140790939331055\n",
            "accuracy:  0.78125\n",
            "Batch 28 loss: 0.7574062347412109\n",
            "accuracy:  0.90625\n",
            "Batch 29 loss: 0.4091638922691345\n",
            "accuracy:  0.78125\n",
            "Batch 30 loss: 0.5336573123931885\n",
            "accuracy:  0.90625\n",
            "Batch 31 loss: 0.22593945264816284\n",
            "accuracy:  0.84375\n",
            "Batch 32 loss: 0.5585534572601318\n",
            "accuracy:  0.90625\n",
            "Batch 33 loss: 0.3147278428077698\n",
            "accuracy:  0.9375\n",
            "Batch 34 loss: 0.19852469861507416\n",
            "accuracy:  0.96875\n",
            "Batch 35 loss: 0.24172765016555786\n",
            "accuracy:  0.875\n",
            "Batch 36 loss: 0.4524770677089691\n",
            "accuracy:  0.9375\n",
            "Batch 37 loss: 0.19594690203666687\n",
            "accuracy:  0.875\n",
            "Batch 38 loss: 0.5554599761962891\n",
            "accuracy:  0.8125\n",
            "Batch 39 loss: 0.5839276313781738\n",
            "accuracy:  0.84375\n",
            "Batch 40 loss: 0.6466413736343384\n",
            "accuracy:  0.875\n",
            "Batch 41 loss: 0.5281699895858765\n",
            "accuracy:  0.84375\n",
            "Batch 42 loss: 0.6104401350021362\n",
            "accuracy:  0.9375\n",
            "Batch 43 loss: 0.2656128406524658\n",
            "accuracy:  0.96875\n",
            "Batch 44 loss: 0.28338348865509033\n",
            "accuracy:  0.84375\n",
            "Batch 45 loss: 0.387889564037323\n",
            "accuracy:  0.875\n",
            "Batch 46 loss: 0.42633479833602905\n",
            "accuracy:  0.84375\n",
            "Batch 47 loss: 0.7254037857055664\n",
            "accuracy:  0.8125\n",
            "Batch 48 loss: 0.4747481346130371\n",
            "accuracy:  0.90625\n",
            "Batch 49 loss: 0.2803734242916107\n",
            "accuracy:  0.875\n",
            "Batch 50 loss: 0.32249361276626587\n",
            "accuracy:  0.90625\n",
            "Batch 51 loss: 0.23261034488677979\n",
            "accuracy:  0.90625\n",
            "Batch 52 loss: 0.3013220727443695\n",
            "accuracy:  0.84375\n",
            "Batch 53 loss: 0.32840198278427124\n",
            "accuracy:  0.9375\n",
            "Batch 54 loss: 0.23463481664657593\n",
            "accuracy:  0.78125\n",
            "Batch 55 loss: 0.7117394208908081\n",
            "accuracy:  0.90625\n",
            "Batch 56 loss: 0.4052267074584961\n",
            "accuracy:  0.78125\n",
            "Batch 57 loss: 0.7173829078674316\n",
            "accuracy:  0.84375\n",
            "Batch 58 loss: 0.4896705746650696\n",
            "accuracy:  0.90625\n",
            "Batch 59 loss: 0.23588350415229797\n",
            "accuracy:  0.75\n",
            "Batch 60 loss: 0.5412742495536804\n",
            "accuracy:  0.90625\n",
            "Batch 61 loss: 0.32411569356918335\n",
            "accuracy:  0.90625\n",
            "Batch 62 loss: 0.363864928483963\n",
            "accuracy:  0.875\n",
            "Batch 63 loss: 0.40796107053756714\n",
            "accuracy:  0.84375\n",
            "Batch 64 loss: 0.393356591463089\n",
            "accuracy:  0.90625\n",
            "Batch 65 loss: 0.3611946403980255\n",
            "accuracy:  0.875\n",
            "Batch 66 loss: 0.39674490690231323\n",
            "accuracy:  0.84375\n",
            "Batch 67 loss: 0.5013803839683533\n",
            "accuracy:  0.78125\n",
            "Batch 68 loss: 0.6575122475624084\n",
            "accuracy:  0.875\n",
            "Batch 69 loss: 0.2884705364704132\n",
            "accuracy:  0.90625\n",
            "Batch 70 loss: 0.34594303369522095\n",
            "accuracy:  0.96875\n",
            "Batch 71 loss: 0.11966967582702637\n",
            "accuracy:  0.9375\n",
            "Batch 72 loss: 0.21395538747310638\n",
            "accuracy:  0.9375\n",
            "Batch 73 loss: 0.14368389546871185\n",
            "accuracy:  0.84375\n",
            "Batch 74 loss: 0.33924442529678345\n",
            "accuracy:  0.96875\n",
            "Batch 75 loss: 0.09547671675682068\n",
            "accuracy:  0.9375\n",
            "Batch 76 loss: 0.20238900184631348\n",
            "accuracy:  0.78125\n",
            "Batch 77 loss: 0.9237396717071533\n",
            "accuracy:  0.875\n",
            "Batch 78 loss: 0.3781660795211792\n",
            "accuracy:  0.9375\n",
            "Batch 79 loss: 0.19772425293922424\n",
            "accuracy:  0.9375\n",
            "Batch 80 loss: 0.3560754060745239\n",
            "accuracy:  0.78125\n",
            "Batch 81 loss: 0.7309447526931763\n",
            "accuracy:  0.8125\n",
            "Batch 82 loss: 0.617108166217804\n",
            "accuracy:  0.875\n",
            "Batch 83 loss: 0.522926926612854\n",
            "accuracy:  0.875\n",
            "Batch 84 loss: 0.32197174429893494\n",
            "accuracy:  0.9375\n",
            "Batch 85 loss: 0.2620285749435425\n",
            "accuracy:  0.84375\n",
            "Batch 86 loss: 0.513953447341919\n",
            "accuracy:  1.0\n",
            "Batch 87 loss: 0.1829899549484253\n",
            "accuracy:  0.875\n",
            "Batch 88 loss: 0.41946882009506226\n",
            "accuracy:  0.9375\n",
            "Batch 89 loss: 0.22830450534820557\n",
            "accuracy:  0.9375\n",
            "Batch 90 loss: 0.14022229611873627\n",
            "accuracy:  0.875\n",
            "Batch 91 loss: 0.28822076320648193\n",
            "accuracy:  0.9375\n",
            "Batch 92 loss: 0.24918344616889954\n",
            "accuracy:  0.8125\n",
            "Batch 93 loss: 0.51104736328125\n",
            "accuracy:  0.96875\n",
            "Batch 94 loss: 0.2505263686180115\n",
            "accuracy:  0.84375\n",
            "Batch 95 loss: 0.537630021572113\n",
            "accuracy:  0.875\n",
            "Batch 96 loss: 0.4983130097389221\n",
            "accuracy:  0.84375\n",
            "Batch 97 loss: 0.37624192237854004\n",
            "accuracy:  0.9375\n",
            "Batch 98 loss: 0.25608664751052856\n",
            "accuracy:  0.9375\n",
            "Batch 99 loss: 0.2137814462184906\n",
            "accuracy:  0.875\n",
            "Batch 100 loss: 0.23502056300640106\n",
            "accuracy:  0.9375\n",
            "Batch 101 loss: 0.18599802255630493\n",
            "accuracy:  0.9375\n",
            "Batch 102 loss: 0.12732815742492676\n",
            "accuracy:  0.96875\n",
            "Batch 103 loss: 0.16603916883468628\n",
            "accuracy:  0.90625\n",
            "Batch 104 loss: 0.36767008900642395\n",
            "accuracy:  0.9375\n",
            "Batch 105 loss: 0.1694672405719757\n",
            "accuracy:  0.96875\n",
            "Batch 106 loss: 0.08038357645273209\n",
            "accuracy:  0.875\n",
            "Batch 107 loss: 0.24480867385864258\n",
            "accuracy:  0.875\n",
            "Batch 108 loss: 0.5049231648445129\n",
            "accuracy:  0.9375\n",
            "Batch 109 loss: 0.10439908504486084\n",
            "accuracy:  0.875\n",
            "Batch 110 loss: 0.3489416241645813\n",
            "accuracy:  0.875\n",
            "Batch 111 loss: 0.4186031222343445\n",
            "accuracy:  0.9375\n",
            "Batch 112 loss: 0.18020519614219666\n",
            "accuracy:  0.875\n",
            "Batch 113 loss: 0.37247270345687866\n",
            "accuracy:  0.9375\n",
            "Batch 114 loss: 0.12413941323757172\n",
            "accuracy:  0.875\n",
            "Batch 115 loss: 0.28676530718803406\n",
            "accuracy:  0.96875\n",
            "Batch 116 loss: 0.16523289680480957\n",
            "accuracy:  0.90625\n",
            "Batch 117 loss: 0.1864679902791977\n",
            "accuracy:  0.875\n",
            "Batch 118 loss: 0.19875921308994293\n",
            "accuracy:  0.96875\n",
            "Batch 119 loss: 0.24460580945014954\n",
            "accuracy:  0.90625\n",
            "Batch 120 loss: 0.25599604845046997\n",
            "accuracy:  0.9375\n",
            "Batch 121 loss: 0.4343632757663727\n",
            "accuracy:  0.90625\n",
            "Batch 122 loss: 0.23090440034866333\n",
            "accuracy:  0.90625\n",
            "Batch 123 loss: 0.22487474977970123\n",
            "accuracy:  0.90625\n",
            "Batch 124 loss: 0.20851102471351624\n",
            "accuracy:  0.96875\n",
            "Batch 125 loss: 0.11939295381307602\n",
            "accuracy:  0.9375\n",
            "Batch 126 loss: 0.3493576943874359\n",
            "accuracy:  0.90625\n",
            "Batch 127 loss: 0.18095138669013977\n",
            "accuracy:  0.90625\n",
            "Batch 128 loss: 0.2396700233221054\n",
            "accuracy:  0.96875\n",
            "Batch 129 loss: 0.13246376812458038\n",
            "accuracy:  0.90625\n",
            "Batch 130 loss: 0.23370662331581116\n",
            "accuracy:  0.9375\n",
            "Batch 131 loss: 0.1295805126428604\n",
            "accuracy:  0.9375\n",
            "Batch 132 loss: 0.283195823431015\n",
            "accuracy:  0.90625\n",
            "Batch 133 loss: 0.3231576085090637\n",
            "accuracy:  0.9375\n",
            "Batch 134 loss: 0.17654526233673096\n",
            "accuracy:  0.9375\n",
            "Batch 135 loss: 0.2885391414165497\n",
            "accuracy:  0.96875\n",
            "Batch 136 loss: 0.09786509722471237\n",
            "accuracy:  0.9375\n",
            "Batch 137 loss: 0.0886731743812561\n",
            "accuracy:  0.9375\n",
            "Batch 138 loss: 0.1196579784154892\n",
            "accuracy:  0.96875\n",
            "Batch 139 loss: 0.1131468415260315\n",
            "accuracy:  0.96875\n",
            "Batch 140 loss: 0.08457435667514801\n",
            "accuracy:  1.0\n",
            "Batch 141 loss: 0.021790066733956337\n",
            "accuracy:  0.9375\n",
            "Batch 142 loss: 0.14420141279697418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-21 15:14:52.922419: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(model.tabulate(rng, jnp.ones((1, 28, 28, 1))))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ts \u001b[38;5;241m=\u001b[39m create_train_state(b, rng, (hp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m1\u001b[39m), hp)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrain_resnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[39], line 7\u001b[0m, in \u001b[0;36mtrain_resnet\u001b[0;34m(train_state)\u001b[0m\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m train_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[38], line 16\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(train_state, X, t)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# function that computes function value and gradient\u001b[39;00m\n\u001b[1;32m     15\u001b[0m grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m (loss, logits), grad \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, get_accuracy(logits, t))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# update parameters\u001b[39;00m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/api.py:751\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m _check_scalar(ans)\n\u001b[1;32m    750\u001b[0m tree_map(partial(_check_output_dtype_grad, holomorphic), ans)\n\u001b[0;32m--> 751\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mvjp_py\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m g \u001b[38;5;241m=\u001b[39m g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(argnums, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m g\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/tree_util.py:488\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/api.py:2163\u001b[0m, in \u001b[0;36m_vjp_pullback_wrapper\u001b[0;34m(name, cotangent_dtypes, cotangent_shapes, io_tree, fun, *py_args_)\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mshape(arg) \u001b[38;5;241m!=\u001b[39m ct_shape:\n\u001b[1;32m   2159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of cotangent input to vjp pullback function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mshape(arg)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust be the same as the shape of corresponding primal input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mct_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2163\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, ans)\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/tree_util.py:488\u001b[0m, in \u001b[0;36m_HashableCallableShim.__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 488\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:150\u001b[0m, in \u001b[0;36mvjp.<locals>.unbound_vjp\u001b[0;34m(pvals, jaxpr, consts, *cts)\u001b[0m\n\u001b[1;32m    148\u001b[0m cts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ct \u001b[38;5;28;01mfor\u001b[39;00m ct, pval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cts, pvals) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pval\u001b[38;5;241m.\u001b[39mis_known())\n\u001b[1;32m    149\u001b[0m dummy_args \u001b[38;5;241m=\u001b[39m [UndefinedPrimal(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars]\n\u001b[0;32m--> 150\u001b[0m arg_cts \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(instantiate_zeros, arg_cts)\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:257\u001b[0m, in \u001b[0;36mbackward_pass\u001b[0;34m(jaxpr, reduce_axes, transform_stack, consts, primals_in, cotangents_in)\u001b[0m\n\u001b[1;32m    254\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m reducing_transposes[eqn\u001b[38;5;241m.\u001b[39mprimitive](\n\u001b[1;32m    255\u001b[0m       reduce_axes, cts_in, \u001b[38;5;241m*\u001b[39minvals, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meqn\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m   cts_out \u001b[38;5;241m=\u001b[39m \u001b[43mget_primitive_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprimitive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcts_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m cts_out \u001b[38;5;241m=\u001b[39m [Zero(v\u001b[38;5;241m.\u001b[39maval) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39minvars] \u001b[38;5;28;01mif\u001b[39;00m cts_out \u001b[38;5;129;01mis\u001b[39;00m Zero \u001b[38;5;28;01melse\u001b[39;00m cts_out\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# FIXME: Some invars correspond to primals!\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/interpreters/ad.py:525\u001b[0m, in \u001b[0;36mlinear_transpose2\u001b[0;34m(transpose_rule, cotangent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlinear_transpose2\u001b[39m(transpose_rule, cotangent, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m Zero \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(cotangent) \u001b[38;5;129;01mis\u001b[39;00m Zero \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtranspose_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcotangent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/lax/lax.py:3447\u001b[0m, in \u001b[0;36m_reshape_transpose_rule\u001b[0;34m(t, operand, new_sizes, dimensions)\u001b[0m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m ad\u001b[38;5;241m.\u001b[39mis_undefined_primal(operand)\n\u001b[1;32m   3446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dimensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3447\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   3448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3449\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [transpose(reshape(t, np\u001b[38;5;241m.\u001b[39mtake(operand\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mshape, dimensions)),\n\u001b[1;32m   3450\u001b[0m                     np\u001b[38;5;241m.\u001b[39margsort(dimensions))]\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/jax/_src/lax/lax.py:867\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(operand, new_sizes, dimensions)\u001b[0m\n\u001b[1;32m    865\u001b[0m   dims \u001b[38;5;241m=\u001b[39m api_util\u001b[38;5;241m.\u001b[39m_ensure_index_tuple(dimensions)\n\u001b[1;32m    866\u001b[0m   same_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(dims) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(np\u001b[38;5;241m.\u001b[39mndim(operand)))\n\u001b[0;32m--> 867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m same_shape \u001b[38;5;129;01mand\u001b[39;00m same_dims \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(operand, Array):\n\u001b[1;32m    868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m type_cast(Array, operand)\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/miniconda3/envs/jaxnn/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1976\u001b[0m, in \u001b[0;36m_shape_dispatcher\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1883\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;124;03m    Return the indices of the elements that are non-zero.\u001b[39;00m\n\u001b[1;32m   1885\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \n\u001b[1;32m   1972\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonzero\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_shape_dispatcher\u001b[39m(a):\n\u001b[1;32m   1977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_shape_dispatcher)\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshape\u001b[39m(a):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train_resnet(train_state):\n",
        "    train, val = get_datasets(hp['num_epochs'], hp['batch_size'])\n",
        "    for i, batch in enumerate(train):\n",
        "        X = jnp.array(batch['image'])\n",
        "        t = jnp.array(batch['label'])\n",
        "\n",
        "        train_state, loss = train_step(train_state, X, t)\n",
        "        print(f'Batch {i} loss: {loss}')\n",
        "\n",
        "model = ResNet(10)\n",
        "# print(model.tabulate(rng, jnp.ones((1, 28, 28, 1))))\n",
        "ts = create_train_state(b, rng, (hp['batch_size'], 28, 28, 1), hp)\n",
        "train_resnet(ts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bb6a2fdd110446c9cd2091f03f67a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f8baae2687948ecadb027983d19e5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c1beed91f74ee4a9bf57df559cc259": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8baae2687948ecadb027983d19e5d2",
            "placeholder": "​",
            "style": "IPY_MODEL_0bb6a2fdd110446c9cd2091f03f67a75",
            "value": " 5/5 [00:00&lt;00:00, 12.57 file/s]"
          }
        },
        "6dc74401b34740ea83c52bbea65cc59e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8ec4941f34424fb07a3a2d84ea6b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8765a3cf9a794530b90291a6b5e41efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a02ed6c7c5e449d3961f6d043b311af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8ec4941f34424fb07a3a2d84ea6b9a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8765a3cf9a794530b90291a6b5e41efe",
            "value": 5
          }
        },
        "b3ed0d5eb68d40c89e878c5d7167c064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e21f270b78654b64a58ac0d150455c07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c4329a8a9341febcfd147e812fb772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc74401b34740ea83c52bbea65cc59e",
            "placeholder": "​",
            "style": "IPY_MODEL_b3ed0d5eb68d40c89e878c5d7167c064",
            "value": "Dl Completed...: 100%"
          }
        },
        "fa8a17fe553c4f059f200553dfd0f5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1c4329a8a9341febcfd147e812fb772",
              "IPY_MODEL_a02ed6c7c5e449d3961f6d043b311af8",
              "IPY_MODEL_31c1beed91f74ee4a9bf57df559cc259"
            ],
            "layout": "IPY_MODEL_e21f270b78654b64a58ac0d150455c07"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
